# -*- coding: utf-8 -*-
import base64
import io
import json
import os
import random
import time
import uuid

import gradio as gr
import requests
from dotenv import load_dotenv
from loguru import logger
from pydub import AudioSegment
from scipy.io import wavfile
from tab_uniaudio_demo import MingOmniTTSDemoTab

# åŠ è½½ .secret æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv(dotenv_path=".secret")

blank_rate, blank_audio_data = wavfile.read("./audio/blank.wav")


# æ¨¡å‹æœåŠ¡ç±» ===========================================================
class SpeechService:
    def __init__(self):
        # API Configuration
        self.use_intranet_api = os.environ.get("USE_INTRANET_API", "false").lower() == "true"

        # WebGW Internet API
        self.WEB_GW_API_URL = os.environ.get("WEB_GW_API_URL")
        self.WEB_GW_API_KEY = os.environ.get("WEB_GW_API_KEY")
        self.WEB_GW_APP_ID = os.environ.get("WEB_GW_APP_ID")

        # Other configs
        self.dump_reqs = os.environ.get("DUMP_REQS", "false").lower() == "true"
        self.sample_rate = 16000  # Gradio expects a sample rate for audio output

        logger.info(f"SpeechService initialized. Using Intranet API: {self.use_intranet_api}")
        if not self.use_intranet_api:
            logger.info(f"WebGW API URL: {self.WEB_GW_API_URL}")
            logger.info(f"WebGW APP ID: {self.WEB_GW_APP_ID}")

    def _call_webgw_api(
        self, call_name: str, call_args: dict, api_project: str = "251220-ming-uniaudio"
    ) -> dict:
        """
        Calls the central WebGW proxy API and transforms the response to match the intranet format.
        """
        if not self.WEB_GW_API_URL or not self.WEB_GW_API_KEY or not self.WEB_GW_APP_ID:
            error_msg = "WebGW API URL, Key, or App ID is not configured in .secret file."
            logger.error(error_msg)
            return {"success": False, "errorMessage": error_msg}

        api_url = self.WEB_GW_API_URL
        request_body = {
            "api_key": self.WEB_GW_API_KEY,
            "api_project": api_project,
            "call_name": call_name,
            "call_token": "token",  # Placeholder
            "call_args": call_args,
        }
        headers = {
            "Content-Type": "application/json",
            "x-webgw-appid": self.WEB_GW_APP_ID,
            "x-webgw-version": "2.0",
        }

        try:
            if self.dump_reqs:
                try:
                    payload_str = json.dumps(request_body, indent=2, ensure_ascii=False)
                    log_message = (
                        f"---- DUMP_REQS (WebGW): Start Request ----\n"
                        f"URL         : {api_url}\n"
                        f"Headers     : {json.dumps(headers, indent=2)}\n"
                        # payload_str may be large, consider truncating if necessary (4KB)
                        f"Payload     : {payload_str[:4096]}{'... [truncated]' if len(payload_str) > 4096 else ''}\n"
                        f"---- DUMP_REQS (WebGW): End Request ----"
                    )
                    logger.info(log_message)
                except Exception as e:
                    logger.warning(
                        f"DUMP_REQS: Failed to serialize WebGW request data for logging: {e}"
                    )

            response = requests.post(api_url, headers=headers, json=request_body, timeout=20)
            response.raise_for_status()

            response_data = response.json()

            # response_data may be large, consider truncating if necessary (4KB)
            logger.info(
                f"WebGW API response data: {json.dumps(response_data, indent=2)[:4096]}{'... [truncated]' if len(json.dumps(response_data)) > 4096 else ''}"
            )

            # response headers
            resp_headers = response.headers
            logger.info(f"WebGW API response headers: {resp_headers}")

            # Transform the WebGW response to mimic the intranet response structure.
            if response_data.get("success"):
                result_obj = response_data.get("resultObj", {})
                inner_result_str = result_obj.get("result", "{}")  # Default to empty JSON string
                return {
                    "success": True,
                    "resultMap": {"result": inner_result_str},
                    "errorMessage": result_obj.get("result_message", ""),
                }
            else:
                # Handle WebGW level errors or model errors proxied through WebGW
                trace_msg = response_data.get("traceMsg")
                error_msg = trace_msg or response_data.get(
                    "errorMessage", "Unknown WebGW API error"
                )
                logger.error(f"WebGW API call failed: {error_msg}")
                return {"success": False, "errorMessage": error_msg}

        except requests.exceptions.RequestException as e:
            logger.error(f"WebGW API request failed: {e}")
            return {"success": False, "errorMessage": f"API request failed: {e}"}
        except json.JSONDecodeError as e:
            logger.error(
                f"Failed to decode WebGW API response JSON: {e}, Response content: {response.text}"
            )
            return {"success": False, "errorMessage": f"Failed to decode API response JSON: {e}"}

    def _preprocess_audio(self, audio_path: str) -> str:
        """
        Conditionally converts an audio file to a 16kHz, single-channel WAV file using pydub.
        Only processes files identified as microphone recordings (e.g., 'audio.wav').
        Returns the path to the converted file, or original path if not processed, or None on failure.
        """
        if not audio_path or not os.path.exists(audio_path):
            logger.error(f"Audio file not found or path is empty: {audio_path}")
            return None

        # Heuristic: Only process if it's a generic recording filename.
        # Assuming 'audio.wav' is the default name for microphone recordings from Gradio.
        if os.path.basename(audio_path) == "audio.wav":
            try:
                logger.info(
                    f"Detected microphone recording: {audio_path}. Starting preprocessing..."
                )
                audio = AudioSegment.from_file(audio_path)

                audio = audio.set_frame_rate(16000).set_channels(1)

                # Export to a new file in the same directory (or a temp one if preferred)
                # Using a distinct name to avoid overwriting original if it's not a temp file
                output_path = f"{os.path.splitext(audio_path)[0]}_16k_mono.wav"
                audio.export(output_path, format="wav")

                logger.info(f"Successfully preprocessed microphone recording to: {output_path}")
                return output_path
            except Exception as e:
                logger.error(f"Failed to preprocess microphone recording '{audio_path}': {e}")
                return None
        else:
            logger.info(
                f"Detected uploaded file: {audio_path}. Skipping preprocessing as per user instruction."
            )
            return audio_path

    def _submit_tts_task(self, payload: dict) -> dict:
        """
        Submits the TTS task to the async endpoint.
        Returns the initial response which should contain the task_id.
        """
        return self._call_webgw_api(call_name="call-non-edit-model", call_args=payload)

    def _poll_tts_result(self, task_id: str) -> dict:
        """Polls the TTS task result."""
        payload = {"task_id": task_id}
        return self._call_webgw_api(call_name="call-non-edit-model", call_args=payload)

    def _submit_edit_task(self, payload: dict) -> dict:
        """
        Submits the Edit task to the async endpoint.
        Returns the initial response which should contain the task_id.
        """
        return self._call_webgw_api(call_name="call-edit-model", call_args=payload)

    def _poll_edit_result(self, task_id: str) -> dict:
        """Polls the Edit task result."""
        payload = {"task_id": task_id}
        return self._call_webgw_api(call_name="call-edit-model", call_args=payload)

    def tts_start_task(self, text: str, prompt_wav_path: str, prompt_text: str) -> str:
        """æäº¤TTSä»»åŠ¡å¹¶è¿”å›task_id"""
        with open(prompt_wav_path, "rb") as f:
            prompt_audio_bytes = f.read()
        prompt_audio_b64 = base64.b64encode(prompt_audio_bytes).decode("utf-8")

        submit_payload = {
            "task_name": "tts",
            "prompt_audio_b64": prompt_audio_b64,
            "text": text,
            "prompt_text": prompt_text,
        }

        # The response from the submission API is the *outer* MPS response
        initial_response = self._submit_tts_task(submit_payload)
        logger.info(f"TTS task submission response: {initial_response}")

        if not initial_response.get("success"):
            return f"é”™è¯¯: {initial_response.get('errorMessage', 'ä»»åŠ¡æäº¤å¤±è´¥')}"

        result_content_str = initial_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "é”™è¯¯: æäº¤å“åº”ä¸­ç¼ºå°‘ 'result' å­—æ®µ"

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return f"é”™è¯¯: {inner_response.get('errMsg', 'å†…éƒ¨APIè°ƒç”¨å¤±è´¥')}"

        task_id = inner_response.get("data", {}).get("task_id")
        if not task_id:
            return "é”™è¯¯: æœªèƒ½ä»å“åº”ä¸­è·å– task_id"

        logger.info(f"TTS task started with ID: {task_id}")
        return task_id

    def tts_check_task(self, task_id: str) -> (str, tuple or None):
        """æ£€æŸ¥TTSä»»åŠ¡çŠ¶æ€å¹¶è¿”å›ç»“æœ"""
        poll_response = self._poll_tts_result(task_id)

        if not poll_response.get("success"):
            return f"é”™è¯¯: {poll_response.get('errorMessage', 'è½®è¯¢å¤±è´¥')}", None

        result_content_str = poll_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "pending", None  # Still pending, no result map yet

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return f"é”™è¯¯: {inner_response.get('errMsg', 'ä»»åŠ¡å¤„ç†å¤±è´¥')}", None

        task_status = inner_response.get("data", {}).get("status")
        if task_status == "pending":
            return "pending", None

        # Task finished, process final audio
        output_audio_b64 = inner_response.get("data", {}).get("output_audio_b64")
        if not output_audio_b64:
            return "é”™è¯¯: ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›éŸ³é¢‘æ•°æ®ã€‚", None

        try:
            decoded_audio_bytes = base64.b64decode(output_audio_b64)
            rate, audio_data = wavfile.read(io.BytesIO(decoded_audio_bytes))
            return "done", (rate, audio_data)
        except Exception as e:
            logger.error(f"Error decoding final audio for task {task_id}: {e}")
            return f"é”™è¯¯: è§£ç éŸ³é¢‘å¤±è´¥ - {e}", None

    def asr_start_task(self, audio_path: str) -> str:
        """æäº¤ASRä»»åŠ¡å¹¶è¿”å›task_id"""
        processed_path = self._preprocess_audio(audio_path)
        if not processed_path:
            return "é”™è¯¯: éŸ³é¢‘é¢„å¤„ç†å¤±è´¥"

        with open(processed_path, "rb") as f:
            audio_bytes = f.read()
        audio_b64 = base64.b64encode(audio_bytes).decode("utf-8")

        submit_payload = {
            "task_name": "asr",
            "audio_b64": audio_b64,
            "messages": [
                {
                    "role": "HUMAN",
                    "content": [
                        {
                            "type": "text",
                            "text": "Please recognize the language of this speech and transcribe it. Format: oral, punctuated.",
                        },
                        {"type": "audio", "audio": "placeholder"},
                    ],
                }
            ],
        }

        # å¤ç”¨é€šç”¨çš„å¼‚æ­¥æäº¤é€»è¾‘
        initial_response = self._submit_tts_task(submit_payload)
        logger.info(f"ASR task submission response: {initial_response}")

        if not initial_response.get("success"):
            return f"é”™è¯¯: {initial_response.get('errorMessage', 'ASR ä»»åŠ¡æäº¤å¤±è´¥')}"

        result_content_str = initial_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "é”™è¯¯: æäº¤å“åº”ä¸­ç¼ºå°‘ 'result' å­—æ®µ"

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return f"é”™è¯¯: {inner_response.get('errMsg', 'å†…éƒ¨APIè°ƒç”¨å¤±è´¥')}"

        task_id = inner_response.get("data", {}).get("task_id")
        if not task_id:
            return "é”™è¯¯: æœªèƒ½ä»å“åº”ä¸­è·å– task_id"

        logger.info(f"ASR task started with ID: {task_id}")
        return task_id

    def asr_check_task(self, task_id: str) -> (str, str or None):
        """æ£€æŸ¥ASRä»»åŠ¡çŠ¶æ€å¹¶è¿”å›ç»“æœ"""
        # å¤ç”¨é€šç”¨çš„å¼‚æ­¥è½®è¯¢é€»è¾‘
        poll_response = self._poll_tts_result(task_id)

        if not poll_response.get("success"):
            return f"é”™è¯¯: {poll_response.get('errorMessage', 'è½®è¯¢å¤±è´¥')}", None

        result_content_str = poll_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "pending", None  # ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ï¼Œå°šæœªè¿”å›ç»“æœ

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return f"é”™è¯¯: {inner_response.get('errMsg', 'ä»»åŠ¡å¤„ç†å¤±è´¥')}", None

        task_status = inner_response.get("data", {}).get("status")
        if task_status == "pending":
            return "pending", None

        # ä»»åŠ¡å®Œæˆï¼Œå¤„ç†æœ€ç»ˆæ–‡æœ¬ç»“æœ
        transcribed_text = inner_response.get("data", {}).get("transcribed_text")
        if transcribed_text is None:  # Use `is None` to allow empty string results
            return "é”™è¯¯: ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›è¯†åˆ«æ–‡æœ¬ã€‚", None

        # APIè¿”å› "Language\tText" æ ¼å¼, æˆ‘ä»¬åªå–æ–‡æœ¬éƒ¨åˆ†
        final_text = transcribed_text.split("\t", 1)[-1]
        return "done", final_text

    def edit_start_task(self, audio_path: str, instruction_text: str) -> str:
        """æäº¤Editä»»åŠ¡å¹¶è¿”å›task_id"""
        processed_path = self._preprocess_audio(audio_path)
        if not processed_path:
            return "é”™è¯¯: éŸ³é¢‘é¢„å¤„ç†å¤±è´¥"

        with open(processed_path, "rb") as f:
            audio_bytes = f.read()
        audio_b64 = base64.b64encode(audio_bytes).decode("utf-8")

        messages = [
            {
                "role": "HUMAN",
                "content": [
                    {"type": "audio", "audio": "placeholder", "target_sample_rate": 16000},
                    {
                        "type": "text",
                        "text": f"<prompt>Please recognize the language of this speech and transcribe it. And {instruction_text}\\n</prompt>",
                    },
                ],
            }
        ]

        submit_payload = {"task_name": "edit", "audio_b64": audio_b64, "messages": messages}

        # è°ƒç”¨ä¸“ç”¨çš„ Edit ä»»åŠ¡æäº¤é€»è¾‘
        initial_response = self._submit_edit_task(submit_payload)
        logger.info(f"Edit task submission response: {initial_response}")

        if not initial_response.get("success"):
            return f"é”™è¯¯: {initial_response.get('errorMessage', 'Edit ä»»åŠ¡æäº¤å¤±è´¥')}"

        result_content_str = initial_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "é”™è¯¯: æäº¤å“åº”ä¸­ç¼ºå°‘ 'result' å­—æ®µ"

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return f"é”™è¯¯: {inner_response.get('errMsg', 'å†…éƒ¨APIè°ƒç”¨å¤±è´¥')}"

        task_id = inner_response.get("data", {}).get("task_id")
        if not task_id:
            return "é”™è¯¯: æœªèƒ½ä»å“åº”ä¸­è·å– task_id"

        logger.info(f"Edit task started with ID: {task_id}")
        return task_id

    def edit_check_task(self, task_id: str) -> (str, str or None, tuple or None):
        """æ£€æŸ¥Editä»»åŠ¡çŠ¶æ€å¹¶è¿”å›ç»“æœ (status, text_result, audio_result)"""
        # è°ƒç”¨ä¸“ç”¨çš„ Edit ä»»åŠ¡è½®è¯¢é€»è¾‘
        poll_response = self._poll_edit_result(task_id)

        if not poll_response.get("success"):
            return "é”™è¯¯", f"è½®è¯¢å¤±è´¥: {poll_response.get('errorMessage', 'æœªçŸ¥é”™è¯¯')}", None

        result_content_str = poll_response.get("resultMap", {}).get("result")
        if not result_content_str:
            return "pending", "ä»»åŠ¡å¤„ç†ä¸­...", None

        if isinstance(result_content_str, str):
            inner_response = json.loads(result_content_str)
        else:
            inner_response = result_content_str

        if inner_response.get("success") != "True":
            return "é”™è¯¯", f"ä»»åŠ¡å¤„ç†å¤±è´¥: {inner_response.get('errMsg', 'æœªçŸ¥é”™è¯¯')}", None

        task_status = inner_response.get("data", {}).get("status")
        if task_status == "pending":
            return "pending", "ä»»åŠ¡å¤„ç†ä¸­...", None

        # ä»»åŠ¡å®Œæˆï¼Œè§£æç»“æœ
        data = inner_response.get("data", {})
        edited_text = data.get("edited_text", "æ¥å£è°ƒç”¨æˆåŠŸä½†æœªè¿”å›æ–‡æœ¬ã€‚")
        output_audio_b64 = data.get("output_audio_b64")

        if not output_audio_b64:
            logger.warning(f"Edit task {task_id} did not return audio data.")
            # è¿”å›ç©ºç™½éŸ³é¢‘
            return "done", edited_text, (blank_rate, blank_audio_data)

        try:
            decoded_audio_bytes = base64.b64decode(output_audio_b64)
            rate, audio_data = wavfile.read(io.BytesIO(decoded_audio_bytes))
            return "done", edited_text, (rate, audio_data)
        except Exception as e:
            logger.error(f"Error decoding final audio for edit task {task_id}: {e}")
            return "é”™è¯¯", f"è§£ç éŸ³é¢‘å¤±è´¥: {e}", None

    # Instruct Model Methods ===========================================
    def submit_instruct_task(self, payload: dict) -> str:
        """æäº¤å¯æ§TTSä»»åŠ¡"""
        # å¤„ç†å‚è€ƒéŸ³é¢‘ (å¦‚æœå­˜åœ¨ä¸”æ˜¯æ–‡ä»¶è·¯å¾„)
        prompt_audio = payload.get("prompt_audio")
        prompt_wav_b64 = None

        if prompt_audio:
            # å¦‚æœå·²ç»æ˜¯ Base64 å­—ç¬¦ä¸²ï¼ˆè™½ç„¶ UI ä¼ é€’çš„é€šå¸¸æ˜¯è·¯å¾„ï¼‰ï¼Œåˆ™ä¿ç•™
            # å¦åˆ™å°è¯•ä½œä¸ºæ–‡ä»¶è·¯å¾„è¯»å–
            if os.path.isfile(prompt_audio):
                processed_path = self._preprocess_audio(prompt_audio)
                if processed_path:
                    with open(processed_path, "rb") as f:
                        prompt_wav_b64 = base64.b64encode(f.read()).decode("utf-8")
                else:
                    return "é”™è¯¯: éŸ³é¢‘æ–‡ä»¶å¤„ç†å¤±è´¥"
            else:
                # å‡è®¾æ˜¯ Base64 æˆ–æ— æ•ˆè·¯å¾„ï¼Œæš‚ä¸å¤„ç†
                pass

        # æ„é€  API å‚æ•°
        call_args = {
            "text": payload.get("text"),
            "caption": payload.get("caption"),
            "seed": payload.get("seed"),
            "prompt_wav_b64": prompt_wav_b64,
        }

        # ç§»é™¤ None å€¼å‚æ•° (æŸäº›æ¨¡å¼ä¸‹ prompt_wav_b64 å¯é€‰)
        call_args = {k: v for k, v in call_args.items() if v is not None}

        response = self._call_webgw_api(
            call_name="submit_task",
            call_args=call_args,
            api_project="260113-ming-uniaudio-instruct",
        )

        if not response.get("success"):
            return f"é”™è¯¯: {response.get('errorMessage', 'æäº¤å¤±è´¥')}"

        result_content = response.get("resultMap", {}).get("result")

        # æ‰“å°æ—¥å¿—
        logger.info(f"Instruct task submission response content: {response}")

        # è§£æå†…éƒ¨ JSON (Maya è¿”å›çš„ç»“æ„)
        if isinstance(result_content, str):
            try:
                result_data = json.loads(result_content)
            except json.JSONDecodeError:
                return f"é”™è¯¯: å“åº”æ ¼å¼æ— æ•ˆ - {result_content}"
        else:
            result_data = result_content

        # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥è¿”å› data ä¸­çš„ task_id
        # Maya è¿”å›æ ¼å¼: { "task_id": "...", "status": "pending" }
        task_id = result_data.get("task_id")
        if not task_id:
            return f"é”™è¯¯: å“åº”ä¸­ç¼ºå°‘ task_id - {result_data}"

        logger.info(f"Instruct task started with ID: {task_id}")

        return task_id

    def poll_instruct_task(self, task_id: str) -> (str, tuple or None):
        """è½®è¯¢å¯æ§TTSä»»åŠ¡ç»“æœ"""
        response = self._call_webgw_api(
            call_name="poll_task",
            call_args={"task_id": task_id},
            api_project="260113-ming-uniaudio-instruct",
        )

        if not response.get("success"):
            return f"é”™è¯¯: {response.get('errorMessage', 'è½®è¯¢è¯·æ±‚å¤±è´¥')}", None

        result_content = response.get("resultMap", {}).get("result")

        if isinstance(result_content, str):
            try:
                result_data = json.loads(result_content)
            except json.JSONDecodeError:
                return f"é”™è¯¯: å“åº”æ ¼å¼æ— æ•ˆ", None
        else:
            result_data = result_content or {}

        status = result_data.get("status")

        if status == "pending":
            return "pending", None
        elif status == "failed":
            return f"é”™è¯¯: {result_data.get('error_message', 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥')}", None
        elif status == "success" or status == "completed":
            output_audio_b64 = result_data.get("output_audio_b64")
            if not output_audio_b64:
                return "é”™è¯¯: ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›éŸ³é¢‘", None
            try:
                decoded_audio = base64.b64decode(output_audio_b64)
                rate, audio_data = wavfile.read(io.BytesIO(decoded_audio))
                return "done", (rate, audio_data)
            except Exception as e:
                logger.error(f"Failed to decode instruct audio: {e}")
                return f"é”™è¯¯: éŸ³é¢‘è§£ç å¤±è´¥ - {e}", None
        else:
            return f"é”™è¯¯: æœªçŸ¥çŠ¶æ€ '{status}'", None


# Gradioç•Œé¢æ„å»º =======================================================
class GradioInterface:
    def __init__(self, speech_service: SpeechService):
        self.service = speech_service

        # åˆå§‹åŒ– UniAudio V4 MOE æ¼”ç¤º Tab
        self.uniaudio_demo_tab = MingOmniTTSDemoTab(
            webgw_url=self.service.WEB_GW_API_URL,
            webgw_api_key=self.service.WEB_GW_API_KEY,
            webgw_app_id=self.service.WEB_GW_APP_ID,
        )

        self.custom_css = """
            .equal-height-group {
                height: 100%;
                min-height: 400px;          /* æœ€å°é«˜åº¦ */
                border: 1px solid #e0e0e0;  /* æ‰å¹³é£æ ¼è¾¹æ¡† */
                border-radius: 4px;         /* ç•¥å¾®åœ†è§’ */
                padding: 16px;
                background-color: #ffffff;  /* å¹²å‡€çš„ç™½è‰²èƒŒæ™¯ */
                box-shadow: none;           /* ç§»é™¤é˜´å½±ä»¥ç¬¦åˆæ‰å¹³é£æ ¼ */
                display: flex;
                flex-direction: column;
                justify-content: space-between; /* å†…å®¹ä¸Šä¸‹åˆ†å¸ƒæ›´æ•´é½ */
                gap: 10px;
            }
            .audio-md {
                background: white !important;
                border: unset !important;
                padding-bottom: 10px;
            }
            input, textarea {
                font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, Courier, monospace !important;
            }
            """
        self.demo = self._create_interface()

    def play_audio(self, content):
        # åŠŸèƒ½æ–¹æ³•ï¼šæ’­æ”¾éŸ³é¢‘ã€‚è¾“å…¥ gr.Audio
        logger.info(f"Playing audio from content: {content}")
        return gr.update(autoplay=True)

    def _create_interface(self) -> gr.Blocks:
        """æ„å»ºGradioç•Œé¢"""

        theme = gr.themes.Soft(
            primary_hue=gr.themes.colors.blue,
            secondary_hue=gr.themes.colors.blue,
            neutral_hue=gr.themes.colors.gray,
            font=["PingFang SC", "SF Pro", "Microsoft YaHei", "Segoe UI", "sans-serif"],
        )
        with gr.Blocks(
            title="Ming-omni-tts æ¼”ç¤º",
            analytics_enabled=False,
            css=self.custom_css,
            theme=theme,
            fill_width=True,
        ) as demo:
            image_path = "figures/ant_bailing2.png"
            try:
                with open(image_path, "rb") as image_file:
                    encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
                base64_src = f"data:image/png;base64,{encoded_string}"
            except Exception:
                base64_src = "data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs="

            with gr.Row(variant="panel", elem_id="header-row"):
                gr.HTML(
                    f"""<div style="position: relative; width: 100%; display: flex; align-items: center; justify-content: center; padding: 10px 0;"><div style="position: absolute; left: 20px; top: 50%; transform: translateY(-50%);"><img src="{base64_src}" alt="Logo" style="height: 60px;"></div><div style="text-align: center;"><h1 style="margin: 0; font-size: 1.8em;">ç™¾çµç³»åˆ— Ming-omni-tts è¯­éŸ³æ¨¡å‹æ¼”ç¤º</h1><p style="margin: 5px 0 0 0; font-size: 1.1em; color: #555;">æä¾›ä¸€ç«™å¼è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³ç¼–è¾‘å’Œè¯­éŸ³åˆæˆèƒ½åŠ›ã€‚ [Ming-v2 ç³»åˆ—](https://huggingface.co/collections/inclusionAI/ming-v2)</p></div></div>"""
                )

            with gr.Tabs():
                # å¼•å…¥ UniAudio V4 MOE ç»¼åˆæ¼”ç¤ºæ ‡ç­¾é¡µ
                self.uniaudio_demo_tab.create_tab()

                with gr.Tab("åŸºç¡€èƒ½åŠ› (ASR/Edit/TTS)"):
                    with gr.Row(equal_height=True):
                        with gr.Column(scale=1, min_width="300px"):
                            with gr.Group(elem_classes="equal-height-group"):
                                gr.Markdown(
                                    "### ğŸ¤ è¯­éŸ³è½¬å†™ï¼ˆASRï¼‰\nå°†æ‚¨ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶è‡ªåŠ¨è½¬å†™ä¸ºæ–‡å­—ã€‚",
                                    elem_classes="audio-md",
                                )
                                asr_task_id_state = gr.State(None)
                                asr_polling_counter = gr.Number(value=0, visible=False)
                                input_audio = gr.Audio(
                                    sources=["upload", "microphone"],
                                    type="filepath",
                                    label="åŸå§‹éŸ³é¢‘",
                                    elem_id="input_audio_player",
                                )
                                btn_input = gr.Button(
                                    "æ’­æ”¾éŸ³é¢‘", elem_id="btn_input_play", variant="secondary"
                                )
                                btn_input.click(
                                    fn=self.play_audio,
                                    inputs=[],
                                    outputs=[],
                                    js="""() => { const playBtn = document.querySelector('#input_audio_player [aria-label=\"Play\"]'); if (playBtn) { playBtn.click(); } }""",
                                )
                                transcription_box = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False)

                        with gr.Column(scale=1, min_width="300px"):
                            with gr.Group(elem_classes="equal-height-group"):
                                gr.Markdown(
                                    "### âœï¸ æ™ºèƒ½ç¼–è¾‘ï¼ˆEditingï¼‰\né€šè¿‡ç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¯¹éŸ³é¢‘å’Œæ–‡æœ¬è¿›è¡Œä¿®æ”¹ã€‚",
                                    elem_classes="audio-md",
                                )
                                edit_task_id_state = gr.State(None)
                                edit_polling_counter = gr.Number(value=0, visible=False)
                                continuous_edit = gr.Checkbox(label="å¯ç”¨è¿ç»­ç¼–è¾‘")
                                instruction_box = gr.Textbox(
                                    label="ç¼–è¾‘æŒ‡ä»¤", placeholder="ä¾‹å¦‚: 'ç»™éŸ³é¢‘é™å™ª'"
                                )
                                submit_btn = gr.Button("æ‰§è¡Œç¼–è¾‘", variant="primary")
                                output_text = gr.Textbox(label="ç¼–è¾‘åæ–‡æœ¬", interactive=False)
                                output_audio = gr.Audio(
                                    label="ç¼–è¾‘åéŸ³é¢‘",
                                    autoplay=True,
                                    interactive=False,
                                    elem_id="output_audio_player",
                                )
                                btn_edit = gr.Button("æ’­æ”¾éŸ³é¢‘", variant="secondary")
                                btn_edit.click(
                                    fn=self.play_audio,
                                    inputs=[],
                                    outputs=[],
                                    js="""() => { const playBtn = document.querySelector('#output_audio_player [aria-label=\"Play\"]'); if (playBtn) { playBtn.click(); } }""",
                                )
                                continuous_btn = gr.Button("è¿ç»­ç¼–è¾‘", visible=False)

                        with gr.Column(scale=1, min_width="300px"):
                            with gr.Group(elem_classes="equal-height-group"):
                                gr.Markdown(
                                    "### ğŸ”Š è¯­éŸ³åˆæˆï¼ˆTTSï¼‰\nä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼Œå…‹éš†å…¶éŸ³è‰²ï¼Œå°†ä»»æ„æ–‡æœ¬åˆæˆä¸ºè‡ªç„¶çš„è¯­éŸ³ã€‚",
                                    elem_classes="audio-md",
                                )
                                prompt_asr_task_id_state = gr.State(None)
                                prompt_asr_polling_counter = gr.Number(value=0, visible=False)
                                task_id_state = gr.State(None)
                                polling_counter = gr.Number(value=0, visible=False)
                                prompt_audio = gr.Audio(
                                    type="filepath", label="å‚è€ƒéŸ³é¢‘", elem_id="prompt_audio_player"
                                )
                                btn_prompt = gr.Button("æ’­æ”¾éŸ³é¢‘", variant="secondary")
                                btn_prompt.click(
                                    fn=self.play_audio,
                                    inputs=[],
                                    outputs=[],
                                    js="""() => { const playBtn = document.querySelector('#prompt_audio_player [aria-label=\"Play\"]'); if (playBtn) { playBtn.click(); } }""",
                                )
                                prompt_text = gr.Textbox(label="å‚è€ƒæ–‡æœ¬", interactive=False)
                                tts_box = gr.Textbox(
                                    label="åˆæˆæ–‡æœ¬", placeholder="è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬"
                                )
                                tts_btn = gr.Button("åˆæˆè¯­éŸ³", variant="primary")
                                synthesized_audio = gr.Audio(
                                    label="åˆæˆéŸ³é¢‘", interactive=False, autoplay=True
                                )
                                btn_tts = gr.Button("æ’­æ”¾éŸ³é¢‘", variant="secondary")
                                btn_tts.click(
                                    fn=self.play_audio,
                                    inputs=[],
                                    outputs=[],
                                    js="""() => { const playBtn = document.querySelector('#synthesized_audio [aria-label=\"Play\"]'); if (playBtn) { playBtn.click(); } }""",
                                )

                    with gr.Row():
                        with gr.Column(scale=2, min_width="600px"):
                            gr.Examples(
                                examples=self._get_examples(),
                                inputs=[input_audio, instruction_box],
                                outputs=[
                                    input_audio,
                                    instruction_box,
                                    transcription_box,
                                    output_text,
                                    output_audio,
                                ],
                                fn=self.process_edit_example,
                                label="è¯­éŸ³ç¼–è¾‘ç¤ºä¾‹",
                                run_on_click=True,
                                cache_examples="lazy",
                            )
                        with gr.Column(scale=1, min_width="300px"):
                            gr.Examples(
                                examples=self._get_tts_examples(),
                                inputs=[prompt_audio, tts_box],
                                outputs=[prompt_audio, tts_box],
                                fn=self.fill_tts_example,
                                label="è¯­éŸ³åˆæˆç¤ºä¾‹",
                                run_on_click=False,
                                cache_examples="lazy",
                            )

            # äº‹ä»¶ç»‘å®š
            input_audio.change(
                self.asr_start_wrapper,
                inputs=[input_audio],
                outputs=[asr_task_id_state, transcription_box, asr_polling_counter],
            )
            asr_polling_counter.change(
                self.asr_check_wrapper,
                inputs=[asr_task_id_state, asr_polling_counter],
                outputs=[transcription_box, asr_polling_counter],
                every=2,
            )

            submit_btn.click(
                self.edit_start_wrapper,
                inputs=[input_audio, instruction_box],
                outputs=[edit_task_id_state, edit_polling_counter, output_text, output_audio],
            )
            edit_polling_counter.change(
                self.edit_check_wrapper,
                inputs=[edit_task_id_state, edit_polling_counter],
                outputs=[output_text, output_audio, edit_polling_counter],
                every=2,
            )

            continuous_edit.change(
                self.toggle_continuous, inputs=continuous_edit, outputs=continuous_btn
            )
            continuous_btn.click(
                self.chain_edit,
                inputs=[output_audio],
                outputs=[input_audio, instruction_box, output_text, output_audio],
            )

            prompt_audio.change(
                self.prompt_asr_start_wrapper,
                inputs=[prompt_audio],
                outputs=[prompt_asr_task_id_state, prompt_text, prompt_asr_polling_counter],
            )
            prompt_asr_polling_counter.change(
                self.prompt_asr_check_wrapper,
                inputs=[prompt_asr_task_id_state, prompt_asr_polling_counter],
                outputs=[prompt_text, prompt_asr_polling_counter],
                every=2,
            )

            tts_btn.click(
                self.tts_start_wrapper,
                inputs=[tts_box, prompt_audio, prompt_text],
                outputs=[task_id_state, synthesized_audio, polling_counter],
            )
            polling_counter.change(
                self.tts_check_wrapper,
                inputs=[task_id_state, polling_counter],
                outputs=[synthesized_audio, polling_counter],
                every=2,
            )

            with gr.Accordion("éº¦å…‹é£æƒé™ä¸å·¥ä½œï¼Ÿç‚¹æˆ‘æŸ¥çœ‹è§£å†³æ–¹æ¡ˆ", open=False):
                gr.Markdown(
                    """
                    å¦‚æœä½ åœ¨ä½¿ç”¨ Chrome æµè§ˆå™¨æ—¶ï¼Œéº¦å…‹é£æƒé™æ— æ³•æ­£å¸¸å·¥ä½œï¼Œä¸”æœ¬åº”ç”¨éƒ¨ç½²åœ¨é HTTPS ç«™ç‚¹ä¸Šï¼Œè¯·å°è¯•ä»¥ä¸‹æ­¥éª¤ï¼š

                    1.  åœ¨ Chrome åœ°å€æ ä¸­è¾“å…¥ `chrome://flags/#unsafely-treat-insecure-origin-as-secure`
                    2.  å°†è¯¥æ ‡å¿—çš„çŠ¶æ€æ”¹ä¸º **Enabled**ã€‚
                    3.  åœ¨å‡ºç°çš„â€œEnabled domainsâ€æˆ–â€œå¯ç”¨çš„åŸŸåâ€è¾“å…¥æ¡†ä¸­ï¼Œè¾“å…¥æœ¬åº”ç”¨çš„åŸŸåã€‚
                    4.  **é‡è¦ï¼š** å½»åº•å…³é—­å¹¶é‡æ–°å¯åŠ¨ Chrome æµè§ˆå™¨ã€‚

                    å®Œæˆè¿™äº›æ­¥éª¤åï¼Œä½ åº”è¯¥å°±èƒ½æˆåŠŸæˆäºˆè¯¥é¡µé¢éº¦å…‹é£æƒé™äº†ã€‚
                """
                )

        return demo

    def _get_tts_examples(self) -> list:
        """è·å–ç¤ºä¾‹æ•°æ®"""
        return [
            [
                "audio/æ—¥å¸¸å¥³å£°.wav",
                "æˆ‘ä»¬å‘ç°ï¼Œå¤§çº¦ä¸‰åˆ†ä¹‹äºŒçš„çŒ«æ›´åå¥½å·¦ä¾§ç¡çœ å§¿åŠ¿ï¼Œè¿™æ ·å®ƒä»¬çš„å·¦ä¾§è§†é‡ã€ä¹Ÿå°±æ˜¯å³è„‘æ§åˆ¶çš„è§†é‡ï¼Œå¯ä»¥æ›´å¥½åœ°è§‚å¯Ÿæ¥è¿‘çš„åŠ¨ç‰©ï¼Œä¸ä¼šè¢«è‡ªå·±çš„èº«ä½“é®æŒ¡ã€‚",
            ],
            [
                "audio/æ—¥å¸¸ç”·å£°.wav",
                "å¤§è¯­è¨€æ¨¡å‹é€šè¿‡å­¦ä¹ æµ·é‡çš„æ–‡æœ¬æ•°æ®ï¼ŒæŒæ¡äº†äººç±»è¯­è¨€çš„å¤æ‚è§„å¾‹ã€‚å®ƒä¸ä»…èƒ½ç²¾å‡†ç†è§£ä½ çš„æŒ‡ä»¤ï¼Œè¿˜èƒ½åƒçœŸäººä¸€æ ·æµç•…åœ°ååŠ©ä½ å†™ä½œæˆ–ç¼–ç¨‹ã€‚",
            ],
            ["audio/ç½—ç¿”.wav", "çœŸæ­£çš„å‹‡æ•¢ï¼Œä¸æ˜¯æ— æ‰€ç•æƒ§ï¼Œè€Œæ˜¯æ˜çŸ¥ææƒ§ä»é€‰æ‹©åšæ­£ç¡®çš„äº‹ã€‚"],
            ["audio/é˜¿æ´›å¨œ.wav", "è€å¸ˆï¼Œæˆ‘è·Ÿä½ è®²å“¦ï¼Œä»Šå¤©å¤©æ°”è¶…~å¥½çš„ï¼"],
        ]

    def _get_examples(self) -> list:
        """è·å–ç¤ºä¾‹æ•°æ®"""
        return [
            ["audio/å¤©æ°”é¢„æŠ¥.wav", "substitute 'éœ€è¦åšå¥½é˜²æš‘å·¥ä½œ' with 'å¤§å®¶èº²åœ¨ç©ºè°ƒæˆ¿é‡Œå°±å¥½äº†ã€‚'"],
            ["audio/åœŸè±†èƒ½ç®—ä¸»é£Ÿå—.wav", "insert 'è¿˜æœ‰å„ç§è èæ±‰å ¡ç­‰ç¦»è°±é£Ÿç‰©ã€‚' at the end"],
            ["audio/é«˜å°”å¤«.wav", "insert 'ç„¶å' before the character or word at index 12"],
            ["audio/å¯æŒç»­å‘å±•.wav", "delete the characters or words from index 3 to index 10"],
            ["audio/ç ä¸‰è§’åŸå¸‚.wav", "delete 'ç ä¸‰è§’åŸå¸‚ç¾¤'"],
            ["audio/å°è¯´æœ—è¯».wav", "substitute 'æå‡' with 'å‰Šå¼±è‡ªå·±çš„'"],
        ]

    # åŒ…è£…å™¨å‡½æ•° =======================================================

    def edit_start_wrapper(self, audio_path: str, instruction: str):
        """è¯­éŸ³ç¼–è¾‘å¼‚æ­¥ä»»åŠ¡å¯åŠ¨åŒ…è£…å™¨"""
        logger.info(
            f"Edit start wrapper called with audio: {audio_path}, instruction: {instruction}"
        )
        if not audio_path or not instruction:
            # è¿”å›å€¼éœ€è¦å¯¹åº” UI outputs: task_id, polling_counter, output_text, output_audio
            return None, 0, "é”™è¯¯: è¯·æä¾›éŸ³é¢‘å’Œç¼–è¾‘æŒ‡ä»¤", (blank_rate, blank_audio_data)

        task_id = self.service.edit_start_task(audio_path, instruction)
        if task_id.startswith("é”™è¯¯:"):
            return None, 0, task_id, (blank_rate, blank_audio_data)

        status_message = f"ç¼–è¾‘ä»»åŠ¡å·²æäº¤ (ID: ...{task_id[-6:]})ï¼Œç­‰å¾…ç»“æœ..."
        # è¿”å› task_id, å¯åŠ¨è½®è¯¢è®¡æ•°å™¨, æ›´æ–°æ–‡æœ¬è¾“å‡ºæ¡†ä¸ºçŠ¶æ€ä¿¡æ¯, æ¸…ç©ºéŸ³é¢‘è¾“å‡º
        return task_id, 1, status_message, gr.update(value=None)

    def edit_check_wrapper(self, task_id: str, polling_counter: int):
        """è¯­éŸ³ç¼–è¾‘å¼‚æ­¥ä»»åŠ¡çŠ¶æ€æ£€æŸ¥åŒ…è£…å™¨"""
        if not task_id or polling_counter == 0:
            # æ²¡æœ‰ä»»åŠ¡æˆ–è½®è¯¢æœªå¯åŠ¨ï¼Œç›´æ¥è¿”å›ï¼Œä¸æ›´æ–°ä»»ä½•å†…å®¹
            return gr.update(), gr.update(), polling_counter

        logger.info(f"Polling Edit task {task_id}, counter: {polling_counter}")
        status, text_result, audio_result = self.service.edit_check_task(task_id)

        if status == "pending":
            elapsed = polling_counter * 2
            status_message = f"ç¼–è¾‘ä¸­... (å·²ç”¨æ—¶ {elapsed}s)"
            # æ›´æ–°æ–‡æœ¬è¾“å‡ºæ¡†ä¸ºçŠ¶æ€ä¿¡æ¯, éŸ³é¢‘ä¸å˜, è½®è¯¢è®¡æ•°å™¨+1
            return status_message, gr.update(), polling_counter + 1
        elif status == "done":
            # è¿”å›æœ€ç»ˆç»“æœ, åœæ­¢è½®è¯¢
            return text_result, audio_result, 0
        else:  # å‘ç”Ÿé”™è¯¯
            # åœ¨æ–‡æœ¬æ¡†æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯, è¿”å›ç©ºç™½éŸ³é¢‘, åœæ­¢è½®è¯¢
            return text_result, audio_result or (blank_rate, blank_audio_data), 0

    def tts_start_wrapper(self, text: str, prompt_wav_path: str, prompt_text: str):
        """è¯­éŸ³åˆæˆä»»åŠ¡å¯åŠ¨åŒ…è£…å™¨"""
        logger.info(
            f"TTS start wrapper called with text length: {len(text)}, prompt_wav_path: {prompt_wav_path}, prompt_text length: {len(prompt_text)}"
        )
        if not all([text, prompt_wav_path, prompt_text]):
            # outputs: [task_id_state, synthesized_audio, polling_counter]
            return None, gr.update(label="é”™è¯¯ï¼šç¼ºå°‘åˆæˆæ–‡æœ¬ã€å‚è€ƒéŸ³é¢‘æˆ–å‚è€ƒæ–‡æœ¬ã€‚", value=None), 0

        task_id = self.service.tts_start_task(text, prompt_wav_path, prompt_text)
        if task_id.startswith("é”™è¯¯:"):
            return None, gr.update(label=task_id, value=None), 0

        status_message = f"ä»»åŠ¡å·²æäº¤ (ID: ...{task_id[-6:]})ï¼Œå¼€å§‹è½®è¯¢..."
        return task_id, gr.update(label=status_message, value=None), 1

    def tts_check_wrapper(self, task_id: str, polling_counter: int):
        """è¯­éŸ³åˆæˆä»»åŠ¡çŠ¶æ€æ£€æŸ¥åŒ…è£…å™¨"""
        if not task_id or polling_counter == 0:
            # outputs: [synthesized_audio, polling_counter]
            return gr.update(), 0

        logger.info(f"Polling TTS task {task_id}, counter: {polling_counter}")
        status, result = self.service.tts_check_task(task_id)

        if status == "pending":
            elapsed = polling_counter * 2  # Approx. 2s per check
            status_message = f"åˆæˆä¸­... ({elapsed}s)"
            return gr.update(label=status_message), polling_counter + 1
        elif status == "done":
            return gr.update(label="åˆæˆæˆåŠŸï¼", value=result), 0
        else:  # Error case
            return gr.update(label=status, value=None), 0

    def asr_start_wrapper(self, audio_path: str):
        """ASR å¼‚æ­¥ä»»åŠ¡å¯åŠ¨åŒ…è£…å™¨"""
        logger.info(f"ASR start wrapper called with audio_path: {audio_path}")
        if not audio_path:
            return None, "é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚", 0

        task_id = self.service.asr_start_task(audio_path)
        if task_id.startswith("é”™è¯¯:"):
            return None, task_id, 0

        status_message = f"è¯†åˆ«ä»»åŠ¡å·²æäº¤ (ID: ...{task_id[-6:]})ï¼Œç­‰å¾…ç»“æœ..."
        # è¿”å› task_id åˆ° state, æ›´æ–°çŠ¶æ€ä¿¡æ¯, å¯åŠ¨è½®è¯¢è®¡æ•°å™¨
        return task_id, status_message, 1

    def asr_check_wrapper(self, task_id: str, polling_counter: int):
        """ASR å¼‚æ­¥ä»»åŠ¡çŠ¶æ€æ£€æŸ¥åŒ…è£…å™¨"""
        if not task_id or polling_counter == 0:
            # æ²¡æœ‰ä»»åŠ¡æˆ–è½®è¯¢æœªå¯åŠ¨ï¼Œç›´æ¥è¿”å›
            return gr.update(), 0

        logger.info(f"Polling ASR task {task_id}, counter: {polling_counter}")
        status, result = self.service.asr_check_task(task_id)

        if status == "pending":
            elapsed = polling_counter * 2  # å‡è®¾è½®è¯¢é—´éš”ä¸º2ç§’
            status_message = f"è¯†åˆ«ä¸­... (å·²ç”¨æ—¶ {elapsed}s)"
            # æ›´æ–°çŠ¶æ€ä¿¡æ¯ï¼Œå¹¶é€’å¢è½®è¯¢è®¡æ•°å™¨ä»¥ç»§ç»­è½®è¯¢
            return status_message, polling_counter + 1
        elif status == "done":
            status_message = "è¯†åˆ«æˆåŠŸï¼"
            # åœæ­¢è½®è¯¢ (polling_counter=0)ï¼Œå¹¶è¿”å›æœ€ç»ˆè¯†åˆ«æ–‡æœ¬
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å°†æœ€ç»ˆç»“æœï¼ˆresultï¼‰å’ŒçŠ¶æ€ä¿¡æ¯ï¼ˆstatus_messageï¼‰éƒ½æ›´æ–°åˆ°åŒä¸€ä¸ªæ–‡æœ¬æ¡†ä¸­ã€‚
            # Gradio ä¼šå°† result è®¾ç½®ä¸ºæ–‡æœ¬æ¡†çš„å€¼ã€‚
            return result, 0
        else:  # å‘ç”Ÿé”™è¯¯
            status_message = f"è¯†åˆ«å¤±è´¥: {status}"
            # åœæ­¢è½®è¯¢ï¼Œå¹¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            return status_message, 0

    def prompt_asr_start_wrapper(self, audio_path: str):
        """ä¸“é—¨ç”¨äºTTSå‚è€ƒéŸ³é¢‘çš„ASRå¼‚æ­¥ä»»åŠ¡å¯åŠ¨åŒ…è£…å™¨"""
        logger.info(f"Prompt ASR start wrapper called with audio_path: {audio_path}")
        if not audio_path:
            # outputs: [task_id_state, output_textbox, polling_counter]
            return None, "é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ å‚è€ƒéŸ³é¢‘ã€‚", 0

        task_id = self.service.asr_start_task(audio_path)
        if task_id.startswith("é”™è¯¯:"):
            return None, task_id, 0

        status_message = f"å‚è€ƒéŸ³é¢‘è¯†åˆ«ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…ç»“æœ..."
        return task_id, status_message, 1

    def prompt_asr_check_wrapper(self, task_id: str, polling_counter: int):
        """ä¸“é—¨ç”¨äºTTSå‚è€ƒéŸ³é¢‘çš„ASRå¼‚æ­¥ä»»åŠ¡çŠ¶æ€æ£€æŸ¥åŒ…è£…å™¨"""
        if not task_id or polling_counter == 0:
            return gr.update(), 0

        logger.info(f"Polling Prompt ASR task {task_id}, counter: {polling_counter}")
        status, result = self.service.asr_check_task(task_id)

        if status == "pending":
            elapsed = polling_counter * 2
            status_message = f"è¯†åˆ«ä¸­... (å·²ç”¨æ—¶ {elapsed}s)"
            return status_message, polling_counter + 1
        elif status == "done":
            return result, 0
        else:  # å‘ç”Ÿé”™è¯¯
            return f"è¯†åˆ«å¤±è´¥: {result}", 0

    # ç•Œé¢äº¤äº’å‡½æ•° =====================================================
    @staticmethod
    def toggle_continuous(is_checked: bool) -> dict:
        """åˆ‡æ¢è¿ç»­ç¼–è¾‘æŒ‰é’®å¯è§æ€§"""
        return gr.update(visible=is_checked)

    @staticmethod
    def chain_edit(current_audio):
        """é“¾å¼ç¼–è¾‘å¤„ç†"""
        if not current_audio:
            return gr.update(), gr.update(), gr.update(), gr.update()
        return (
            gr.update(value=current_audio),  # æ›´æ–°input_audio
            gr.update(value=""),  # æ¸…ç©ºinstruction
            gr.update(value=""),  # æ¸…ç©ºoutput_text
            gr.update(value=None),  # æ¸…ç©ºoutput_audio
        )

    def fill_tts_example(self, audio_path: str, text: str) -> tuple:
        """å¡«å……TTSç¤ºä¾‹æ•°æ®"""
        # This is for run_on_click=False, it just populates the fields
        return audio_path, text

    def process_edit_example(self, audio_path: str, instruction: str) -> tuple:
        # Populate input fields
        updated_input_audio = gr.update(value=audio_path)
        updated_instruction_box = gr.update(value=instruction)

        # ASR
        transcription = self.service.asr_start_task(audio_path)
        updated_transcription_box = gr.update(value=transcription)

        # Editing
        edited_text, (rate, audio_data) = self.service.edit_voice(
            audio_path, instruction, transcription
        )
        updated_output_text = gr.update(value=edited_text)
        updated_output_audio = gr.update(value=(rate, audio_data))

        return (
            updated_input_audio,
            updated_instruction_box,
            updated_transcription_box,
            updated_output_text,
            updated_output_audio,
        )

    @staticmethod
    def chain_edit(current_audio):
        """é“¾å¼ç¼–è¾‘å¤„ç†"""
        if not current_audio:
            return gr.update(), gr.update(), gr.update(), gr.update()
        return (
            gr.update(value=current_audio),  # æ›´æ–°input_audio
            gr.update(value=""),  # æ¸…ç©ºinstruction
            gr.update(value=""),  # æ¸…ç©ºoutput_text
            gr.update(value=None),  # æ¸…ç©ºoutput_audio
        )

    def fill_example(self, audio_path: str, instruction: str) -> tuple:
        """å¡«å……ç¤ºä¾‹æ•°æ®"""
        return (
            audio_path,
            instruction,
            gr.update(value=""),
            gr.update(value=""),
            gr.update(value=None),
        )

    def process_edit_example(self, audio_path: str, instruction: str):
        # Populate input fields
        yield gr.update(value=audio_path), gr.update(
            value=instruction
        ), "æ­£åœ¨æäº¤è¯†åˆ«ä»»åŠ¡...", gr.update(), gr.update()

        # --- ASR Task ---
        asr_task_id = self.service.asr_start_task(audio_path)
        if asr_task_id.startswith("é”™è¯¯:"):
            yield gr.update(), gr.update(), asr_task_id, gr.update(), gr.update()
            return

        yield gr.update(), gr.update(), "è¯†åˆ«ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…ç»“æœ...", gr.update(), gr.update()

        transcription = ""
        for i in range(30):  # Timeout after 60s
            time.sleep(2)
            status, result = self.service.asr_check_task(asr_task_id)
            if status == "pending":
                yield gr.update(), gr.update(), f"è¯†åˆ«ä¸­... ({(i+1)*2}s)", gr.update(), gr.update()
            elif status == "done":
                transcription = result
                yield gr.update(), gr.update(), transcription, gr.update(), gr.update()
                break
            else:  # Error
                yield gr.update(), gr.update(), f"è¯†åˆ«å¤±è´¥: {result}", gr.update(), gr.update()
                return

        if not transcription:
            yield gr.update(), gr.update(), "è¯†åˆ«è¶…æ—¶æˆ–æœªè¿”å›ç»“æœ", gr.update(), gr.update()
            return

        # --- Edit Task ---
        yield gr.update(), gr.update(), transcription, "æ­£åœ¨æäº¤ç¼–è¾‘ä»»åŠ¡...", gr.update(value=None)

        edit_task_id = self.service.edit_start_task(audio_path, instruction)
        if edit_task_id.startswith("é”™è¯¯:"):
            yield gr.update(), gr.update(), transcription, f"ç¼–è¾‘ä»»åŠ¡æäº¤å¤±è´¥: {edit_task_id}", (
                blank_rate,
                blank_audio_data,
            )
            return

        yield gr.update(), gr.update(), transcription, "ç¼–è¾‘ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…ç»“æœ...", gr.update(
            value=None
        )

        for i in range(60):  # Timeout after 120s
            time.sleep(2)
            status, text_result, audio_result = self.service.edit_check_task(edit_task_id)
            if status == "pending":
                yield gr.update(), gr.update(), transcription, f"ç¼–è¾‘ä¸­... ({(i+1)*2}s)", gr.update()
            elif status == "done":
                yield gr.update(), gr.update(), transcription, text_result, audio_result
                return
            else:  # Error
                yield gr.update(), gr.update(), transcription, f"ç¼–è¾‘å¤±è´¥: {text_result}", audio_result or (
                    blank_rate,
                    blank_audio_data,
                )
                return

        yield gr.update(), gr.update(), transcription, "ç¼–è¾‘ä»»åŠ¡è¶…æ—¶", (
            blank_rate,
            blank_audio_data,
        )

    def launch(self):
        """å¯åŠ¨Gradioåº”ç”¨"""
        server_name = os.getenv("GRADIO_APP_HOST", "127.0.0.1")
        server_port = int(os.getenv("GRADIO_APP_PORT", "7860"))
        self.demo.launch(share=False, server_name=server_name, server_port=server_port)


# ä¸»ç¨‹åº ==============================================================
if __name__ == "__main__":
    # åˆå§‹åŒ–æœåŠ¡
    speech_service = SpeechService()

    # åˆ›å»ºå¹¶å¯åŠ¨Gradioç•Œé¢
    gradio_interface = GradioInterface(speech_service)
    gradio_interface.demo.queue(default_concurrency_limit=10).launch()
